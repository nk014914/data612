---
title: "Data 612 - Discussion 3"
author: "Natalie Kalukeerthie"
date: "2025-06-17"
output: html_document
---

### As more systems and sectors are driven by predictive analytics, there is increasing awareness of the possibility and pitfalls of algorithmic discrimination. In what ways do you think Recommender Systems reinforce human bias? Reflecting on the techniques we have covered, do you think recommender systems reinforce or help to prevent unethical targeting or customer segmentation?  Please provide one or more examples to support your arguments.

Recommender systems, while designed to personalize user experiences, often reinforce human biases because they learn from historical data that may already reflect societal inequalities. Techniques like collaborative filtering rely on past user behavior, which can enforce stereotypes. For example, recommending different music genres based on racial assumptions rooted in previous listening patterns. Content-based filtering, on the other hand, tends to create "filter bubbles" by repeatedly recommending similar content. These systems also exhibit popularity bias, amplifying already-popular content and marginalizing minority creators.In Equality of Opportunity in Supervised Learning by Moritz Hardt, Eric Price, and Nathan Srebro (2016) it's argued that fairness in algorithmic decision-making should ensure that individuals who are equally qualified have equal chances of receiving positive outcomes. This principle is highly relevant to recommender systems, which can unintentionally provide unequal opportunities, such as promoting job ads or educational content more frequently to certain demographic groups over others. Although fairness-aware approaches can mitigate these issues, such as by applying equal opportunity constraints or adjusting for historical bias, I believe that most standard recommender systems lack these safeguards as these issues are brought to light in many platforms. As a result, they often contribute to unethical customer segmentation and reinforce existing societal inequities rather than prevent them. 